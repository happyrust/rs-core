#!/usr/bin/env python3
"""
ä» IDA Pro æå–æ‰€æœ‰ Noun ç±»å‹å®šä¹‰

åŸºäº core.dll ä¸­çš„å…¨å±€å­—ç¬¦ä¸²
ä½œè€…: AI Analysis Tool
æ—¥æœŸ: 2025
"""

import json
import re
from pathlib import Path

# ä» IDA Pro list_globals_filter æå–çš„æ‰€æœ‰ aNoun å­—ç¬¦ä¸²
# è¿™äº›æ˜¯æ‰‹åŠ¨å¤åˆ¶çš„ IDA Pro è¾“å‡º
NOUN_STRINGS = """
aNounAbox3qbvdb
aNounAccpnt3qbv
aNounAccset3qbv
aNounAcdt3qbvdb
aNounAcone3qbvd
aNounAcr3qbvdbN
aNounAcrl3qbvdb
aNounAcrst3qbvd
aNounAcrule3qbv
aNounAcrw3qbvdb
aNounAcstyl3qbv
aNounActi3qbvdb
aNounActn3qbvdb
aNounActo3qbvdb
aNounActor3qbvd
aNounAcyli3qbvd
aNounAdde3qbvdb
aNounAdim3qbvdb
aNounAdir3qbvdb
aNounAdish3qbvd
aNounAextr3qbvd
aNounAhu3qbvdbN
aNounAidarc3qbv
aNounAidcir3qbv
aNounAidgro3qbv
aNounAidlin3qbv
aNounAidpoi3qbv
aNounAidtex3qbv
aNounBend3qbvdb
aNounBran3qbvdb
aNounCable3qbvd
aNounCap3qbvdbN
aNounCirc3qbvdb
aNounCone3qbvdb
aNounCoup3qbvdb
aNounCyli3qbvdb
aNounDamp3qbvdb
"""

def extract_noun_names(noun_strings: str) -> dict:
    """ä» IDA Pro å­—ç¬¦ä¸²ä¸­æå– Noun åç§°"""
    
    nouns = {}
    lines = [line.strip() for line in noun_strings.strip().split('\n') if line.strip()]
    
    for line in lines:
        # æå– Noun åç§°ï¼šaNoun{NAME}3qbv...
        # æ¨¡å¼ï¼šaNoun + å¤§å†™å­—æ¯å¼€å¤´çš„åç§° + 3qbv
        match = re.match(r'aNoun([A-Z][a-z]{2,}).*', line)
        if match:
            noun_name = match.group(1).upper()
            nouns[noun_name] = {
                'string_name': line,
                'identified': True
            }
        else:
            # å¦‚æœæ˜¯ç‰¹æ®Šæ ¼å¼ï¼ˆå¦‚ aNounCap3qbvdbNï¼‰
            match2 = re.match(r'aNoun([A-Z][a-z]{1,3}).*', line)
            if match2:
                noun_name = match2.group(1).upper()
                nouns[noun_name] = {
                    'string_name': line,
                    'identified': True
                }
    
    return nouns

def generate_complete_noun_list(output_path: str):
    """ç”Ÿæˆå®Œæ•´çš„ Noun åˆ—è¡¨"""
    
    print("="*70)
    print(" "*15 + "ä» IDA Pro æå–æ‰€æœ‰ Noun ç±»å‹")
    print("="*70)
    
    # æå– Noun åç§°
    nouns = extract_noun_names(NOUN_STRINGS)
    
    print(f"\nâœ… æå–åˆ° {len(nouns)} ä¸ª Noun ç±»å‹:")
    for name in sorted(nouns.keys()):
        print(f"   - {name}")
    
    # åŸºäº PDMS æ ‡å‡†æ·»åŠ å±‚çº§å…³ç³»
    hierarchy = {
        "WORL": ["SITE"],
        "SITE": ["ZONE"],
        "ZONE": ["EQUI", "STRU"],
        "EQUI": ["PIPE", "BRAN"],
        "PIPE": ["BEND", "CAP", "CONE", "COUP", "CYLI", "DAMP"],
        "BRAN": ["BEND", "CAP", "CONE", "COUP", "CYLI"],
    }
    
    # ç”Ÿæˆè¾“å‡º
    output_data = {
        "version": "4.0",
        "source": "IDA Pro core.dll å…¨å±€å­—ç¬¦ä¸²æå–",
        "description": "ä» core.dll æå–çš„æ‰€æœ‰ Noun ç±»å‹å®šä¹‰ï¼ˆä¸ä¾èµ– JSONï¼‰",
        "extraction_method": "åˆ†æ IDA Pro ä¸­çš„ aNoun* å…¨å±€å­—ç¬¦ä¸²å˜é‡",
        "nouns": nouns,
        "hierarchy": hierarchy,
        "statistics": {
            "total_nouns": len(nouns),
            "identified_nouns": len([n for n in nouns.values() if n.get('identified')]),
            "hierarchy_relations": sum(len(v) for v in hierarchy.values())
        }
    }
    
    # ä¿å­˜æ–‡ä»¶
    output_file = Path(output_path)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    for key, value in output_data['statistics'].items():
        print(f"   - {key}: {value}")
    
    return output_data


def main():
    """ä¸»å‡½æ•°"""
    output_path = "/Volumes/DPC/work/plant-code/rs-core/all_nouns_from_ida.json"
    
    result = generate_complete_noun_list(output_path)
    
    print("\n" + "="*70)
    print(" "*25 + "âœ¨ æå–å®Œæˆï¼")
    print("="*70)


if __name__ == "__main__":
    main()
